\documentclass[11pt,letterpaper]{article}
\usepackage{fullpage}
\usepackage[top=3cm, bottom=2cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{lastpage}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{hyperref,booktabs}
\usepackage{float}
\linespread{1.3}
\usepackage{caption,subcaption}
\usepackage{minted}
\usepackage[T1]{fontenc}
\usepackage{fontawesome}
\usepackage{float}
\usepackage{cleveref}
\usepackage{enumitem}
\usepackage[utf8]{inputenc}
\emergencystretch=1em

\usepackage[style=authoryear-comp,maxbibnames=9,maxcitenames=1,uniquelist=false,backend=biber]{biblatex}
\addbibresource{references.bib}
% \DeclareNameAlias{default}{family-given}


\hypersetup{%
  colorlinks=true,
  linkcolor=blue,
  linkbordercolor={0 0 1}
}

\title{\huge \textbf{RPE Proposal}}
\date{}
\author{Rohit Murali \and Supervisor: Cristina Conati}
\begin{document}

\maketitle

\section{Background and Motivation}

Emotions play a large part in learning. Studies  \autocite{baker2010better, wortha2019multiple} show that emotions can affect learning in Intelligent Tutoring Systems (ITSs). This encourages educators to design ITSs which can adapt to a student's emotions during their interaction \autocite{woolf2009affect, grawemeyer2016affecting}. These systems require detecting the user's affective state to an extent during learning, and there is research in this area that tries to predict emotion valence through interaction data \autocite{lalle2018prediction}, single emotion using eye-tracking data \autocite{jaques2014predicting,sims2020neural} and co-occurring emotions \autocite{lalle2021predict}. This proposal outlines a research idea focused on predicting co-occurring emotions during learning with the ITS, MetaTutor \autocite{azevedo2013using}. Prediction tasks with MetaTutor are usually done by collecting students' eye-tracking and interaction data. \autocite{lalle2021predict} predicts pairs of co-occurring emotions (Boredom and Frustration; Curiosity and Anxiety) using eye-tracking and interaction data with MetaTutor. This paper shows that eye-tracking and interaction data used in isolation can predict the co-occurrence of the two emotion pairs significantly better than a baseline. This work was done as part of an RA project that started in Winter Term 1 2020.

\section{Proposed Project}
We will extend the task of predicting co-occuring emotions using eye-tracking and interaction data in \autocite{lalle2021predict} by combining two datasets of different user studies with MetaTutor; the study used in \autocite{lalle2018prediction}, and the study used in \autocite{lalle2021predict} and \autocite{jaques2014predicting} with . Both studies involve university students who learn about the circulatory system through MetaTutor. The students' gazes are tracked with eye-trackers and asked to self-report their emotions at different stages of the experiment in both studies. The dataset in \autocite{lalle2021predict} has valid eye-tracking data for 270 self-reports and valid interaction data for 325 self-reports. The dataset in \autocite{lalle2018prediction} has valid eye-tracking for 126 self-reports and valid interaction data for 176 self-reports. The two studies are structurally similar, so it makes sense to attempt to merge the two datasets, however, there are variations among the studies that makes this task non-trivial. These include structural differences, such as the time intervals between emotion reports and number of emotion reports asked per student, and measurement differences, such as the type of eye-tracker used. We restrict our prediction tasks to pairs of co-occurring emotions as higher-order classification tasks might be too hard considering the limited size of the dataset. The first part of this RPE project involves identifying these differences in detail, coming up with a way to combine the two datasets, and choosing the right pair(s) of co-occurring emotions for prediction tasks, which may be different from those in \autocite{lalle2021predict}.

With the larger dataset (\textit{MetaTutor dataset} onward), the next step of the RPE project is to deploy machine-learning models for the 4-way classification task related to the emotion pairs we decide are suitable. We will use the random forest (RF) and logistic regression (LR) classifiers used in \autocite{lalle2021predict} on the MetaTutor dataset as a baseline since they are the current existing standard in literature for the task of predicting co-occurring emotions. In \autocite{lalle2021predict}, we found that simple feature fusion of the two types of data did not improve performance. So we plan on investigating an ensemble classifier involving the RF and LR models trained on the different data sources, eye-tracking and interaction data. Moreover, with a larger dataset, deep-learning models may work well and so we will evaluate the performance of a fully-connected neural network and later VTnet \autocite{sims2020neural} compared to the ensemble and baseline classifiers.

The last part of the project involves investigating the feasibility of the VTnet architecture \autocite{sims2020neural}, used in a different context of users interacting with ValueChart \autocite{carenini2004valuecharts}, on the MetaTutor dataset. The VTnet architecture used in \autocite{sims2020neural} uses raw eye-tracking data, including scan-paths, to classify user confusion by connecting the outputs of an Recurrent Neural Network (RNN) and a Convolutional Neural Network (CNN) and sending them to a fully-connected neural network. This part of the project will involve a novel upgrade to the VTnet architecture by including both eye-tracking and interaction data as inputs to the network, and assessing its performance against the other models.

\section{Timeline}

A proposed timeline of the project will be as follows.

\begin{itemize}
    \item \textbf{May to Mid-June:} Identify differences between the two datasets and understand how to combine them.

    \item \textbf{Mid-June to Mid-July:} Evaluate performance of the ensemble model and the fully-connected neural network to the current models in literature, namely the RF and LR models in \autocite{lalle2021predict}.

    \item \textbf{Mid-July to End-August:} Upgrade VTnet architecture to include interaction data and assess its performance.

\end{itemize}

\printbibliography
\end{document}
